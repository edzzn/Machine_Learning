{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DataSet\n",
    "\n",
    "The \"Hello world\" of Machine Learning is \"MNIST\"\n",
    "\n",
    "## What is MNIST?\n",
    "\n",
    "MNIST is a computer vision dataset of images of handwritten digits.\n",
    "\n",
    "![Handwritten Digits](https://www.tensorflow.org/images/MNIST.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression\n",
    "The original code of the tutorial can be found here:  [mnist_softmax.py](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/examples/tutorials/mnist/mnist_softmax.py)\n",
    "\n",
    ">The Softmax Regression or multinomial logistic regression is a generalization of the logistic regression to the case where we want to handle multiple classes. [[UFLDL Tutorial - Stanford.edu](http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/)]\n",
    "\n",
    "The __Softmax Regression__ has two steps:\n",
    "\n",
    "1. We add up the evidence of our input being in certain classes\n",
    "1. Then we convert that evidence into probabilities\n",
    "\n",
    "Simple Representation of the Softmax Regression\n",
    "![SoftMax Regression](https://www.tensorflow.org/images/softmax-regression-scalargraph.png)\n",
    "\n",
    "\n",
    "If we write the Softmax Regression as an equation we have:\n",
    "![Softmax Regression Equation](https://www.tensorflow.org/images/softmax-regression-vectorequation.png)\n",
    "\n",
    "__y = softmax(Wx + b)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "# one-hot vectors: A vector which is 0 in most dimensions, and 1 in a single dimension.\n",
    "# [0,0,0,1,0,0,0,0,0] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __MNIST__ data is split into three parts: 55,000 data points of training _mnist.train_, 10,000 points of test data (_`mnist.test`_) and 5,000 points of validation data (_`mnist.validation`_)\n",
    "\n",
    "The MNIST data has the images of the handwritten numbers __X__ (_`mnist.train.images`_) and a maping of a label for each image __y__ (_`mnist.train.labels`_).\n",
    "\n",
    "Each image is a 28px by 28px. It can be interpreted as an array of numbers. This vector has 28x28 = 784 numbers.\n",
    "\n",
    "![Array Numbers](https://www.tensorflow.org/images/MNIST-Matrix.png)\n",
    "\n",
    "mnist.train.images : [55000, 784]\n",
    "mnist.train.labels : [55000, 10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Regression\n",
    "TensorFlow lets us describe a graph of interacting operations that run outside of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "# None means that a dimension can be of any lenght"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable is a modifiable tensor. It can be used and modified by the computation. We initialize __W__ and __b__ as tensors full of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "1. Multiply __x__ and __w__\n",
    "1. Add __b__\n",
    "1. Apply __tf.nn.softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "In ML we define the __cost__ or __lost__ represents how far off out model is from the desired outcome. The goal is to minimize the error.\n",
    "\n",
    "We'll implement cross-entropy. Info on [Cross-entropy](http://colah.github.io/posts/2015-09-Visual-Information/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# implement the cross-entropy function\n",
    "# cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "# The funtion above is numerically unstable\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "# To reduce the loss we can choose a optimization algorithm.\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We minimize the cross entropy using GradiantDescent with a learning rate of 0.05.\n",
    "\n",
    "This shifts each variable a little in the direction that reduces the cost the most. [List of Optimization Algorithms](https://www.tensorflow.org/api_guides/python/train#Optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lauch the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# We initialize our variables\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Run the training step 1000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "__y__ : Label Preductions\n",
    "\n",
    "**y_** : Correct Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9191\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_:mnist.test.labels}))\n",
    "\n",
    "# Save session info and close the session\n",
    "# We write the summary to be able to visualize it in tensorboard\n",
    "writer = tf.summary.FileWriter('./MNIST', sess.graph)\n",
    "writer.close\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source\n",
    "This notebook follows the [MNIST For ML Beginners](https://www.tensorflow.org/get_started/mnist/beginners) by [TensorFlow](https://www.tensorflow.org/)\n",
    "\n",
    "The porpuse of this notebook is to help me comprehend the use of TensorFlow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
